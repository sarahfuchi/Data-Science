![Getting Started with a Movie Recommendation System](/images/movie/movie0.jpg)

This project focuses on movie recommendation systems, using the TMDB 5000 movie dataset and taking inspiration from public notebooks.

# Table of Contents
1. [Chapter 1 - Project Overview](#ch1)
1. [Chapter 2 - Types of recommendation systems](#ch2)
1. [Chapter 3 - Step 1: Data Gathering](#ch3)
1. [Chapter 4 - Step 2: Demographic Filtering](#ch4)
1. [Chapter 5 - Step 3: Content Based Filtering](#ch5)
1. [Chapter 6 - Step 4: Collaborative Filtering](#ch6)
1. [References](#ch90)


<a id="ch1"></a>
# Project Overview

The growing number of data collections is leading to a new era of information. Data is used to build better systems, and this is where recommendation systems come into play. Recommendation systems are a type of information filtering systems because they improve the quality of search results and provide items that are more relevant or related to the search item or search history of the user.

Almost every major tech company uses them in one form or another: Amazon uses them to suggest products to customers, YouTube uses them to decide which video to play next on autoplay, and Facebook uses them to recommend pages. Moreover, companies like Netflix and Spotify depend heavily on the effectiveness of their recommendation systems for their business and success.

<a id="ch2"></a>
# Types of recommendation systems

There are basically three types of recommender systems:

- Demographic Filtering- Netflix offers recommendations to every user, based on what movies are popular or in a specific genre. The System recommends similar movies to users who have similar demographic features. Since each person is different, this approach is considered to be too simplistic.The basic idea behind this system is that movies that are more popular and critically acclaimed will have a higher probability of being liked by the average audience.

- Content Based Filtering- They suggest similar items based on the item that one have selected. This system uses metadata about items, such as genre, director, description, and actors. The basic idea behind these recommender systems is that if someone liked an item, they're likely to like other items similar to it.

- Collaborative Filtering- This system matches people with similar interests and provides recommendations based on this matching. Collaborative filters don't require metadata like content-based filters do.

<a id="ch3"></a>
# Step 1: Data Gathering and info from Kaggle

# About Dataset
What can we say about the success of a movie before it is released? Do you have a consistent formula for making decisions? Given that big-budget films can still fail, this question is more important than ever to the movie industry. Movie fans may have different interests, so can we anticipate which films will be highly rated, whether they are commercial success or not?

This is a great place to start digging in to those questions, with data on the plot, cast, crew, budget, and revenues of several thousand films.

# Data Sets

I worked with two datasets: tmdb_5000_credits.csv and tmdb_5000_movies.csv

The first dataset contains the following features:

- movie_id - A unique identifier for each movie.
- cast - The name of lead and supporting actors.
- crew - The name of Director, Editor, Composer, Writer etc.

The second dataset has the following features:

- budget - The budget in which the movie was made.
- genre - The genre of the movie, Action, Comedy ,Thriller etc.
- homepage - A link to the homepage of the movie.
- id - This is infact the movie_id as in the first dataset.
- keywords - The keywords or tags related to the movie.
- original_language - The language in which the movie was made.
- original_title - The title of the movie before translation or adaptation.
- overview - A brief description of the movie.
- popularity - A numeric quantity specifying the movie popularity.
- production_companies - The production house of the movie.
- production_countries - The country in which it was produced.
- release_date - The date on which it was released.
- revenue - The worldwide revenue generated by the movie.
- runtime - The running time of the movie in minutes.
- status - "Released" or "Rumored".
- tagline - Movie's tagline.
- title - Title of the movie.
- vote_average - average ratings the movie recieved.
- vote_count - the count of votes recieved.

I joined the two datasets on the 'id' column.

```
df1.columns = ['id','tittle','cast','crew']
df2= df2.merge(df1,on='id')
```

Take a look at the data: 
```
df2.head(10)
```
![First look at the data](/images/movie/movie1.jpg)

I found [this paper](https://www.ijert.org/research/recommender-systems-types-of-filtering-techniques-IJERTV3IS110197.pdf) that was helpful in understanding recommendations systems and the filtering techniques. Then I looked into three filtering techniques:

![Filtering Techniques](/images/movie/movie2.jpg)


<a id="ch4"></a>
# Step 2: Demographic Filtering

Demographic filtering (DF) is a process of categorizing people and recommending services based on their demographic information. DF user profiles are built by grouping individuals into archetypes that describe the common characteristics of different user groups. [This paper](https://link.springer.com/article/10.1023/A:1022850703159) provides further information about DF. DF is a service that is used by semi-trusted third parties to recommend services to specific consumers based on data about them.

DF tracks customer buying behavior across different categories, and groups customers with similar demographic traits into groups. For a new user, suggestions are generated by first determining which category he belongs to, and then applying the cumulative purchasing preferences of prior users to that category.The Demographic approach does not require a history of user ratings unlike collaborative and content-based technique.

We need a way to score or rate a movie, calculate the score for each movie, and order the scores. We also need a way to propose the highest rated movie to users. Therefore, I'll use IMDB's weighted rating (wr), which is as follows:

![IMDB's weighted rating (wr)](/images/movie/movie3.jpg)

Where v is the total number of votes for the movie. The number of votes required to be included in the chart is m. The movie's rating is R and the average vote for the entire report is C.

We already have v (number of votes) and R (average number of votes), so C is calculated simply:

```
C= df2['vote_average'].mean()
C
```

6.092171559442011

The average rating for all of the movies is around a 6 on a scale of 10. The next step is to choose an appropriate value for m, which is the number of votes needed to be included in the chart. We will choose the 90th percentile as our cutoff. In other words, a movie needs to get more votes than at least 90% of the other movies on the list in order to be included in the chart.

```
m= df2['vote_count'].quantile(0.9)
m
```

1838.4000000000015

We can now filter the movies that are eligible for the chart.

```
q_movies = df2.copy().loc[df2['vote_count'] >= m]
q_movies.shape
```

(481, 26)

There are a total of 481 movies that meet the criteria for inclusion in this list. We will need to determine a metric to measure each qualified movie. We'll create a weighted rating() function to calculate the value of a new feature score, which will be applied to our DataFrame of qualified movies.

```
def weighted_rating(x, m=m, C=C):
    v = x['vote_count']
    R = x['vote_average']
    return (v/(v+m) * R) + (m/(m+v) * C)
```

Create a new feature called "score" and calculate its value using the "weighted_rating()" function.

```
q_movies['score'] = q_movies.apply(weighted_rating, axis=1)
```

Then, sort the DataFrame by the score feature and output the top 15 movies' title, vote count, vote average, and weighted rating or score. The index has been reset:

```
q_movies = q_movies.sort_values('score', ascending=False)
q_movies[['title', 'vote_count', 'vote_average', 'score']].head(15)
```
![Top 15 movies](/images/movie/movie4.jpg)

We've made a recommendation for the first time. We can identify movies that are very popular right now on these systems, and we can find them by sorting the dataset by the popularity column.

```
pop= df2.sort_values('popularity', ascending=False)
import matplotlib.pyplot as plt
plt.figure(figsize=(12,4))

plt.barh(pop['title'].head(6),pop['popularity'].head(6), align='center',
        color='skyblue')
plt.gca().invert_yaxis()
plt.xlabel("Popularity")
plt.title("Popular Movies")
```

![Popular movies](/images/movie/movie5.jpg)

Please note that these demographic recommender systems recommend all users with a generic chart of recommended movies. They do not care about what the user wants or prefers. We may be able to fix this issue when we switch to a more advanced system called content-based filtering.

<a id="ch5"></a>
# Step 3: Content Based Filtering

![Content Based Filtering](/images/movie/movie6.jpg)

Content-based filtering makes recommendations based on user preferences for product features. Content-based filtering is an important area of research that continues to develop and expand. It is considered to be the continuation of information fromÂ filtering research: [Belkin et al.'s paper](https://dl.acm.org/doi/abs/10.1145/138859.138861). 

In a CBF system, objects of interest are defined by their associated features. Text recommendation systems, such as newsgroup filtering systems, use words in the text as features.The content-based recommender builds a profile of user interests based on the features contained in the objects rated by the user, known as "item-to-item relevance", which determines the type of user profile based on the learning method used. Decision trees, neural nets, and vector-based representations have all been used in decision-making.

[In a study of Web documents](https://www.aaai.org/Papers/Symposia/Spring/1996/SS-96-05/SS96-05-010.pdf), users assign a value to each one on a two-point scale, with "hot" representing a high value and "cold" representing a low value. These ratings are then used to determine the likelihood of words appearing in hot or cold documents based on user ratings.Then there is WebWatcher, which monitors user actions and link selections on web pages to recommend links on web pages that the user may visit in the future. Unlike collaborative filtering, the CBF is not as complicated because all that is required is an analysis of the things that an independent user has purchased or seen.

* Plot description based Recommender

Based on plot descriptions, I analyzed pairwise similarity scores between all movies and made recommendations based on those values. The dataset's overview feature includes a plot explanation that provides additional detail about the data. Let's take a closer look at the data:

```
df2['overview'].head(10)
```
![plot descriptions](/images/movie/movie7.jpg)

To understand what the text is about, we look for words that are commonly used. Term frequency measures how often a particular word or phrase appears in a text. Luckely, the scikit-learn library provides a built-in TfIdfVectorizer class that can produce a TF-IDF matrix in a few lines of code. However more info on TF-IDF can be seen here: [A Gentle Introduction To Calculating The TF-IDF Values](https://towardsdatascience.com/a-gentle-introduction-to-calculating-the-tf-idf-values-9e391f8a13e5)

```
from sklearn.feature_extraction.text import TfidfVectorizer

tfidf = TfidfVectorizer(stop_words='english')

df2['overview'] = df2['overview'].fillna('')

tfidf_matrix = tfidf.fit_transform(df2['overview'])

tfidf_matrix.shape
```

(4803, 20978)

We found that the 4800 movies in our dataset were described with over 20,000 different words. We can now compute a similarity score using this matrix. There are three possible similarity scores for this: the euclidean, Pearson, and cosine scores. There is no "right" answer when it comes to which score is the best.Different scores work well in different situations, so it's a good idea to experiment with different measures.

A numerical value will be created that represents the similarity between two movies. We use the cosine similarity score because it is independent of magnitude and is reasonably simple and quick to calculate. It is defined mathematically as follows:

![Cosine Similarity Score](/images/movie/movie7.jpg)

The dot product calculation gave me the cosine similarity score because I used the TF-IDF vectorizer. As a result, I implemented linear kernel() from sklearn instead of cosine similarity() because it's quicker.

```
from sklearn.metrics.pairwise import linear_kernel

cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)
```

After further processing the data, I was able to find the index of a movie by its title, get a list of cosine similarity ratings for that movie compared to all other movies. Then, convert it to a tuple list, where the first element is the position and the second is the similarity value. Then sort the  list of tuples based on the similarity scores. Followed by noting the top ten items on this list.I ignored the first element because it's about the self (the movie most similar to a particular movie is the movie itself). I then found the titles that correspond to the top elements' indices.

Let's check out the results for the movie 'Inception'

```
get_recommendations('Inception')
```

![get_recommendations('Inception')](/images/movie/movie8.jpg)


```
get_recommendations('The Godfather')
```

![get_recommendations('The Godfather')](/images/movie/movie9.jpg)

Our system was able to locate similar movies with plot descriptions, but the quality of the recommendations wasn't great. Better metadata can help improve the quality of our recommender system. That is exactly what I did in this part. The data used to generate a recommender for movie viewers was the top three actors, the director, relative genres and narrative keywords.

I needed to extract the three most important actors, directors, and keywords related to the movie from the cast, crew, and keyword features. Our data is currently stored in a format that I need to change into a more secure and usable structure. After that, I developed functions to help me extract the essential data from each feature.

![Actors, directors, and keywords](/images/movie/movie10.jpg)

The names and keyword instances were then converted to lowercase and any spaces between them removed. This is done in order to ensure that the first names of any name, such as "Nancy", are not confused by the system. That way, our vectorizer does not confuse "Nancy Brown" and "Nancy Mitchell". I created the metadata soup, which included all the metadata I wanted to provide to the vectorizer (namely, the names of actors, director, and keywords).

The steps for creating this improved recommender were identical to those using the plot description-based recommender. I used CountVectorizer() instead of TF-IDF, which was a significant difference. This is because I didn't want to underestimate the existence of the actor or director just because the actor or director appeared or directed more movies. By providing a new cosine_sim2 matrix as a second input, I was able to reuse my get_recommendations() function:

```
get_recommendations('Inception', cosine_sim2)
```
![get_recommendations('Inception', cosine_sim2)](/images/movie/movie11.jpg)

```
get_recommendations('The Godfather', cosine_sim2)
```

![get_recommendations('The Godfather', cosine_sim2)](/images/movie/movie12.jpg)

The increased metadata has allowed our recommender to gather more information and provide us with better recommendations as seen for Inception and The Godfather movies. 

<a id="ch6"></a>
# Step 4: Collaborative Filtering



<a id="ch90"></a>
# References
I would like to express gratitude for the following resources, and thank developers for the inspiration:

* [Getting Started with a Movie Recommendation System](https://www.kaggle.com/code/ibtesama/getting-started-with-a-movie-recommendation-system/notebook) 
* [Recommender Systems: Types of Filtering Techniques](https://www.ijert.org/research/recommender-systems-types-of-filtering-techniques-IJERTV3IS110197.pdf)
* [A Taxonomy of Recommender Agents on the Internet](https://link.springer.com/article/10.1023/A:1022850703159)
* [Information Filtering and Information Retrieval: Two Sides of the Same Coin?](https://dl.acm.org/doi/abs/10.1145/138859.138861)
* [Syskill & Webert: Identifying interesting web sites](https://www.aaai.org/Papers/Symposia/Spring/1996/SS-96-05/SS96-05-010.pdf)





